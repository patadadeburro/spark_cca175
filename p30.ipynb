{"cells":[{"cell_type":"markdown","source":["# CCA175 Practice Exam\n* Exam    : CCA175\n* Title   : CCA Spark and Hadoop Developer Exam\n* Vendor  : Cloudera\n* Version : V12.35\n\nIT Certification Guaranteed, The Easy Way!"],"metadata":{}},{"cell_type":"markdown","source":["## NO.30 CORRECT TEXT\n### Problem Scenario 28 : \n\nYou need to implement near real time solutions for collecting information\nwhen submitted in file with below Data"],"metadata":{}},{"cell_type":"code","source":["echo \"IBM,100,20160104\" >> /tmp/spooldir2/.bb.txt\necho \"IBM,103,20160105\" >> /tmp/spooldir2/.bb.txt\nmv /tmp/spooldir2/.bb.txt /tmp/spooldir2/bb.txt"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["After few mins"],"metadata":{}},{"cell_type":"code","source":["echo \"IBM,100.2,20160104\" >> /tmp/spooldir2/.dr.txt\necho \"IBM,103.1,20160105\" >> /tmp/spooldir2/.dr.txt\nmv /tmp/spooldir2/.dr.txt /tmp/spooldir2/dr.txt"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["You have been given below directory location (if not available than create it) \n\n`/tmp/spooldir2`"],"metadata":{}},{"cell_type":"markdown","source":["As soon as file committed in this directory that needs to be available in hdfs in\n\n`/tmp/flume/primary` as well as \n\n`/tmp/flume/secondary` location."],"metadata":{}},{"cell_type":"markdown","source":["However, note that `/tmp/flume/secondary` is optional, \nif transaction failed which writes in this directory need not to be rollback."],"metadata":{}},{"cell_type":"markdown","source":["Write a flume configuration file named `p30.conf` and use it to load data in hdfs with following\nadditional properties .\n\n1. Spool /tmp/spooldir2 directory\n2. File prefix in hdfs sholuld be `events`\n3. File suffix should be `.log`\n4. If file is not committed and in use than it should have `_` as prefix.\n5. Data should be written as text to hdfs"],"metadata":{}},{"cell_type":"code","source":["\n### Answer:\n\nSee the explanation for Step by Step Solution and configuration.\nExplanation:\nSolution :\nStep 1 : Create directory mkdir /tmp/spooldir2\nStep 2 : Create flume configuration file, with below configuration for source, sink and channel and\nsave it in p30.conf.\n\nagent1 .sources = source1\nagent1.sinks = sink1a sink1b\nagent1.channels = channel1a channel1b\n\nagent1.sources.source1.channels = channel1a channel1b\nagent1.sources.source1.selector.type = replicating\nagent1.sources.source1.selector.optional = channel1b\n\nagent1.sinks.sink1a.channel = channel1a\nagent1 .sinks.sink1b.channel = channel1b\n\nagent1.sources.source1.type = spooldir\nagent1 .sources.sourcel.spoolDir = /tmp/spooldir2\n\nagent1.sinks.sink1a.type = hdfs\nagent1 .sinks, sink1a.hdfs. path = /tmp/flume/primary\nagent1 .sinks.sink1a.hdfs.filePrefix = events\nagent1 .sinks.sink1a.hdfs.fileSuffix = .log\nagent1 .sinks.sink1a.hdfs.fileType = Data Stream\n\nagent1 .sinks.sink1b.type = hdfs\nagent1 .sinks.sink1b.hdfs.path = /tmp/flume/secondary\nagent1 .sinks.sink1b.hdfs.filePrefix = events\nagent1.sinks.sink1b.hdfs.fileSuffix = .log\nagent1 .sinks.sink1b.hdfs.fileType = Data Stream\nagent1.channels.channel1a.type = file\nagent1.channels.channel1b.type = memory\n\nstep 4 : Run below command which will use this configuration file and append data in hdfs.\nStart flume service:\nflume-ng agent -conf /home/cloudera/flumeconf -conf-file\n/home/cloudera/flumeconf/p30.conf --name age\n\nStep 5 : Open another terminal and create a file in /tmp/spooldir2/\necho \"IBM,100,20160104\" > /tmp/spooldir2/.bb.txt\necho \"IBM,103,20160105\" > /tmp/spooldir2/.bb.txt mv /tmp/spooldir2/.bb.txt\n/tmp/spooldir2/bb.txt\nAfter few mins\necho \"IBM.100.2,20160104\" >/tmp/spooldir2/.dr.txt\necho \"IBM,103.1,20160105\" > /tmp/spooldir2/.dr.txt mv /tmp/spooldir2/.dr.txt\n/tmp/spooldir2/dr.txt"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["#### Answer"],"metadata":{}},{"cell_type":"markdown","source":["create local directory `/tmp/spooldir2`\n\nin linux console"],"metadata":{}},{"cell_type":"code","source":["mkdir /tmp\nmkdir /tmp/spooldir2"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["create directores in hdfs"],"metadata":{}},{"cell_type":"code","source":["hdfs dfs -mkdir /tmp/flume\nhdfs dfs -mkdir /tmp/flume/primary\nhdfs dfs -mkdir /tmp/flume/secondary"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["create the p30.conf file"],"metadata":{}},{"cell_type":"code","source":["a1.sources                      = r1\na1.sinks                        = k1 k2\na1.channels                     = c1 c2\n\n# sources\na1.sources.r1.channels          = c1 c2\na1.sources.r1.type              = spooldir\na1.sources.r1.spoolDir          = /tmp/spooldir2\na1.sources.r1.selector.type     = replicating\na1.sources.r1.selector.optional = c2\n\n# sinks\na1.sinks.k1.channel             = c1\na1.sinks.k1.type                = hdfs\na1.sinks.k1.hdfs.path           = /tmp/flume/primary\na1.sinks.k1.hdfs.filePrefix     = event\na1.sinks.k1.hdfs.fileSuffix     = .log\na1.sinks.k1.hdfs.fileType       = DataStream\n\na1.sinks.k2.channel             = c2\na1.sinks.k2.type                = hdfs\na1.sinks.k2.hdfs.path           = /tmp/flume/secondary\na1.sinks.k2.hdfs.filePrefix     = event\na1.sinks.k2.hdfs.fileSuffix     = .log\na1.sinks.k2.hdfs.fileType       = DataStream\n\n# channels\na1.channels.c1.type             = file\na1.channels.c2.type             = memory\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["#### Start flume service:\nRun below command which will use this configuration file and append data in hdfs."],"metadata":{}},{"cell_type":"code","source":["flume-ng agent\n--conf /home/cloudera/flumeconf \n--conf-file /home/cloudera/flumeconf/p30.conf \n--name a1"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["flume-ng agent --conf /home/cloudera/flumeconf --conf-file /home/cloudera/flumeconf/p30.conf --name a1"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["#### send data.\nOpen another terminal and type the next commands"],"metadata":{}},{"cell_type":"code","source":["echo \"IBM,100,20160104\" >> /tmp/spooldir2/.bb.txt\necho \"IBM,103,20160105\" >> /tmp/spooldir2/.bb.txt\nmv /tmp/spooldir2/.bb.txt /tmp/spooldir2/bb.txt"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["After few mins, send the next data"],"metadata":{}},{"cell_type":"code","source":["echo \"IBM,100.2,20160104\" >> /tmp/spooldir2/.dr.txt\necho \"IBM,103.1,20160105\" >> /tmp/spooldir2/.dr.txt\nmv /tmp/spooldir2/.dr.txt /tmp/spooldir2/dr.txt"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["end\n---"],"metadata":{}}],"metadata":{"name":"p30","notebookId":3939867850322609},"nbformat":4,"nbformat_minor":0}
