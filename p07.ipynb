{"cells":[{"cell_type":"markdown","source":["# CCA175 Practice Exam\n* Exam    : CCA175\n* Title   : CCA Spark and Hadoop Developer Exam\n* Vendor  : Cloudera\n* Version : V12.35\n\nIT Certification Guaranteed, The Easy Way!"],"metadata":{}},{"cell_type":"markdown","source":["## NO.7 CORRECT TEXT\n### Problem Scenario 35 : \nYou have been given a file named spark/EmployeeName.csv\n\n|id | name |\n|-|-|\n|E01 | Lokesh  |\n|E02 | Bhupesh |\n|E03 | Amit    |\n|E04 | Ratan   |\n|E05 | Dinesh  |\n|E06 | Pavan   |\n|E07 | Tejas   |\n|E08 | Sheela  |\n|E09 | Kumar   |\n|E10 | Venkat  |"],"metadata":{}},{"cell_type":"markdown","source":["1. Load this file from hdfs and sort it by name and save it back as (id,name) in results directory.\n\nHowever, make sure while saving it should be able to write In a single file."],"metadata":{}},{"cell_type":"markdown","source":["#### Answer"],"metadata":{}},{"cell_type":"markdown","source":["See the explanation for Step by Step Solution and configuration.\nExplanation:\n\nSolution:\nStep 1 : Create file in hdfs (We will do using Hue). However, you can first create in local filesystem\nand then upload it to hdfs.\n\nStep 2 : Load EmployeeName.csv file from hdfs and create PairRDDs\nval name = sc.textFile(\"spark7/EmployeeName.csv\")\nval namePairRDD = name.map(x=> (x.split(\",\")(0),x.split(\",\")(1)))\n\nStep 3 : Now swap namePairRDD RDD.\nval swapped = namePairRDD.map(item => item.swap)\n\nstep 4: Now sort the rdd by key.\nval sortedOutput = swapped.sortByKey()\n\nStep 5 : Now swap the result back\nval swappedBack = sortedOutput.map(item => item.swap}\n\nStep 6 : Save the output as a Text file and output must be written in a single file.\nswappedBack. repartition(1).saveAsTextFile(\"spark7/result.txt\")"],"metadata":{}},{"cell_type":"markdown","source":["Solution: \n#### Step 1 : \nCreate file in hdfs (We will do using Hue). \nHowever, you can first create in local filesystem and then upload it to hdfs."],"metadata":{}},{"cell_type":"code","source":["# now the EmployeeName.csv exist in my local computer \nhdfs dfs -put EmployeeName.csv /spark/EmployeeName"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["#### Step 2 : \nLoad EmployeeName.csv file from hdfs and create PairRDDs"],"metadata":{}},{"cell_type":"code","source":["val name        = sc.textFile( \"/spark/EmployeeName.csv\" ) \nval namePairRDD = name.map( x=> ( x.split(\",\")(0), x.split(\",\")(1) ) )"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["#### Step 3 : \nNow swap namePairRDD RDD."],"metadata":{}},{"cell_type":"code","source":["val swapped = namePairRDD.map(item => item.swap)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["#### step 4: \nNow sort the rdd by key."],"metadata":{}},{"cell_type":"code","source":["val sortedOutput = swapped.sortByKey()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["#### Step 5 : \nNow swap the result back"],"metadata":{}},{"cell_type":"code","source":["val swappedBack = sortedOutput.map(item => item.swap)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["#### Step 6 : \nSave the output as a Text file and output must be written in a single file."],"metadata":{}},{"cell_type":"code","source":["swappedBack.repartition(1).saveAsTextFile( \"spark/result.txt\" )"],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"p07","notebookId":233748014513879},"nbformat":4,"nbformat_minor":0}
