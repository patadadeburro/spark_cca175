{"cells":[{"cell_type":"markdown","source":["# CCA175 Practice Exam\n* Exam    : CCA175\n* Title   : CCA Spark and Hadoop Developer Exam\n* Vendor  : Cloudera\n* Version : V12.35\n\nIT Certification Guaranteed, The Easy Way!"],"metadata":{}},{"cell_type":"markdown","source":["## NO.14 CORRECT TEXT\n### Problem Scenario 68 : \n\nYou have given a file as below.\n\n`spark75/file1.txt`\n\nFile contain some text. As given Below"],"metadata":{}},{"cell_type":"code","source":["Apache Hadoop is an open-source software framework written in Java for distributed storage and\ndistributed processing of very large data sets on computer clusters built from commodity hardware.\nAll the modules in Hadoop are designed with a fundamental assumption that hardware failures are\ncommon and should be automatically handled by the framework\nThe core of Apache Hadoop consists of a storage part known as Hadoop Distributed File\nSystem (HDFS) and a processing part called MapReduce. Hadoop splits files into large blocks and\ndistributes them across nodes in a cluster. To process data, Hadoop transfers packaged code for\nnodes to process in parallel based on the data that needs to be processed.\nhis approach takes advantage of data locality nodes manipulating the data they have access to to\nallow the dataset to be processed faster and more efficiently than it would be in a more conventional\nsupercomputer architecture that relies on a parallel file system where computation and data are\ndistributed via high-speed networking\nFor a slightly more complicated task, lets look into splitting up sentences from our documents into\nword bigrams. A bigram is pair of successive tokens in some sequence.\nWe will look at building bigrams from the sequences of words in each sentence, and then try to find\nthe most frequently occuring ones."],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["The first problem is that values in each partition of our initial RDD describe lines from the file rather\nthan sentences. Sentences may be split over multiple lines. \n\nThe glom() RDD method is used to create a single entry for each document containing the list of all lines, we can then join the lines up, then resplit them into sentences using \".\" as the separator, using flatMap so that every object in our RDD\nis now a sentence.\n\nA bigram is pair of successive tokens in some sequence. Please build bigrams from the sequences of\nwords in each sentence, and then try to find the most frequently occuring ones."],"metadata":{}},{"cell_type":"markdown","source":["Answer"],"metadata":{}},{"cell_type":"markdown","source":["See the explanation for Step by Step Solution and configuration.\nExplanation:\nSolution :\n\nStep 1 : Create all three tiles in hdfs (We will do using Hue}. However, you can first create in local\nfilesystem and then upload it to hdfs.\n\nStep 2 : The first problem is that values in each partition of our initial RDD describe lines from the file\nrather than sentences. Sentences may be split over multiple lines.\nThe glom() RDD method is used to create a single entry for each document containing the list of all\nlines, we can then join the lines up, then resplit them into sentences using \".\" as the separator, using\nflatMap so that every object in our RDD is now a sentence.\nsentences = sc.textFile(\"spark75/file1.txt\") \\ .glom() \\\nmap(lambda x: \" \".join(x)) \\ .flatMap(lambda x: x.spllt(\".\"))\n\nStep 3 : Now we have isolated each sentence we can split it into a list of words and extract the word\nbigrams from it. Our new RDD contains tuples containing the word bigram (itself a tuple containing\nthe first and second word) as the first value and the number 1 as the second value. bigrams =\nsentences.map(lambda x:x.split())\n\\ .flatMap(lambda x: [((x[i],x[i+1]),1)for i in range(0,len(x)-1)])\n\nStep 4 : Finally we can apply the same reduceByKey and sort steps that we used in the wordcount\nexample, to count up the bigrams and sort them in order of descending frequency. In reduceByKey\nthe key is not an individual word but a bigram.\nfreq_bigrams = bigrams.reduceByKey(lambda x,y:x+y)\\\nmap(lambda x:(x[1],x[0])) \\\nsortByKey(False)\nfreq_bigrams.take(10)"],"metadata":{}},{"cell_type":"markdown","source":["#### Step 1 : \nCreate all three tiles in hdfs (We will do using Hue}. However, you can first create in local filesystem and then upload it to hdfs."],"metadata":{}},{"cell_type":"markdown","source":["#### Step 2 : \nThe first problem is that values in each partition of our initial RDD describe lines from the file rather than sentences. Sentences may be split over multiple lines. The glom() RDD method is used to create a single entry for each document containing the list of all lines, we can then join the lines up, then resplit them into sentences using \".\" as the separator, using flatMap so that every object in our RDD is now a sentence."],"metadata":{}},{"cell_type":"code","source":["sentences = sc.textFile(\"spark75/file1.txt\") \\ \n            .glom() \\ \n            .map( lambda x: \" \".join( x ) ) \\ \n            .flatMap( lambda x: x.split( \".\" ) )"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["#### Step 3 : \nNow we have isolated each sentence we can split it into a list of words and extract the word bigrams from it. Our new RDD contains tuples containing the word bigram (itself a tuple containing the first and second word) as the first value and the number 1 as the second value."],"metadata":{}},{"cell_type":"code","source":["bigrams = sentences.map( lambda x: x.split() ) \\ \n          .flatMap( lambda x: [ ( (x[i],x[i+1]),1) for i in range(0,len(x)-1) ] )"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#data   = [ 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',  ]\ndata    =  map(chr, range(97, 123) )\nbigrams = [ ( ( data[i], data[i+1] ),1) for i in range(0,len( data )-1) ]\n\n\nprint( data)\nfor i in b: print( i )"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"p14","notebookId":3981825967983583},"nbformat":4,"nbformat_minor":0}
