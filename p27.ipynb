{"cells":[{"cell_type":"markdown","source":["# CCA175 Practice Exam\n* Exam    : CCA175\n* Title   : CCA Spark and Hadoop Developer Exam\n* Vendor  : Cloudera\n* Version : V12.35\n\nIT Certification Guaranteed, The Easy Way!"],"metadata":{}},{"cell_type":"markdown","source":["## NO.27 CORRECT TEXT\n### Problem Scenario 39 : \nYou have been given two files"],"metadata":{}},{"cell_type":"markdown","source":["`spark16/file1.txt`"],"metadata":{}},{"cell_type":"code","source":["1,9,5\n2,7,4\n3,8,3"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["`spark16/file2.txt`"],"metadata":{}},{"cell_type":"code","source":["1,g,h\n2,i,j\n3,k,l"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Load these two tiles as Spark RDD and join them to produce the below results\n\n(l,((9,5),(g,h)))\n\n(2, ((7,4), (i,j))) \n\n(3, ((8,3), (k,l)))\n\nAnd write code snippet which will sum the second columns of above joined results (5+4+3)."],"metadata":{}},{"cell_type":"markdown","source":["#### Answer frim the book\nSee the explanation for Step by Step Solution and configuration.\nExplanation:\nSolution :\nStep 1 : Create tiles in hdfs using Hue.\n\nStep 2 : Create pairRDD for both the files.\n\nval one = sc.textFile(\"spark16/file1.txt\")\n.map{ _.split(\",\",-1) match { case Array(a, b, c) => (a, ( b, c)) } }\n\nval two = sc.textFHe(Mspark16/file2.txt\")\n.map{ _ .split('7\\-1) match { case Array(a, b, c) => (a, (b, c)) } }\n\nStep 3 : Join both the RDD. val joined = one.join(two)\n\nStep 4 : Sum second column values.\n\nval sum = joined.map { case (_, ((_, num2), (_, _))) => num2.tolnt }.reduce(_ + _)"],"metadata":{}},{"cell_type":"markdown","source":["#### Answer in scala"],"metadata":{}},{"cell_type":"markdown","source":["load data"],"metadata":{}},{"cell_type":"code","source":["# val txt1 = sc.textFile( 'p27/text1.txt' ).map{ _.split( \",\" ) match { Array (a, b, c) => ( a, ( b, c ) ) } }\n\nval txt1 = sc.textFile( 'p27/text1.txt' ).map( _.split( \",\" ) ).map( a => ( a(0), ( a(1), a(2) ) ) )\nval txt2 = sc.textFile( 'p27/text2.txt' ).map( _.split( \",\" ) ).map( a => ( a(0), ( a(1), a(2) ) ) )"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["join the two RDDs"],"metadata":{}},{"cell_type":"code","source":["val j = txt1.join( txt2 )"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["make sum"],"metadata":{}},{"cell_type":"code","source":["val sum_2_col = j.map{ case ( k, (n, s) ) => n._2.toInt }.sum()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["#### Answer in python"],"metadata":{}},{"cell_type":"markdown","source":["load data"],"metadata":{}},{"cell_type":"code","source":["txt1 = sc.textFile( 'p27/text1.txt' ).map( lambda line: line.split( ',' ) ).map( lambda a: (a[0], (a[1], a[2]) ) )\ntxt2 = sc.textFile( 'p27/text2.txt' ).map( lambda line: line.split( ',' ) ).map( lambda a: (a[0], (a[1], a[2]) ) )"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["txt1.take( 5 )\ntxt2.take( 5 )"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["join the two RDDs"],"metadata":{}},{"cell_type":"code","source":["j = txt1.join( txt2 )\nj.take( 10 )"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["make sum"],"metadata":{}},{"cell_type":"code","source":["sum_2_col = j.map( lambda (k, (n, s) ):  int( n[1] ) ).sum() \nsum_2_col"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["end\n---"],"metadata":{}}],"metadata":{"name":"p27","notebookId":1288568939140870},"nbformat":4,"nbformat_minor":0}
