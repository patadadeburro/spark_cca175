{"cells":[{"cell_type":"markdown","source":["# CCA175 Practice Exam\n* Exam    : CCA175\n* Title   : CCA Spark and Hadoop Developer Exam\n* Vendor  : Cloudera\n* Version : V12.35\n\nIT Certification Guaranteed, The Easy Way!"],"metadata":{}},{"cell_type":"markdown","source":["## NO.21 CORRECT TEXT\n### Problem Scenario 10 : \n\nYou have been given following mysql database details as well as other info.\n\n| attribute | value |\n|-|-|\n| user | retail_dba\n| password  | cloudera\n| database  | retail_db\n| jdbc URL | jdbc:mysql://quickstart:3306/retail_db\n\nPlease accomplish following:\n\n1 . Create a database named `hadoopexam` and then create a table named `departments` in it, with following fields. \n\n  * department_id int, \n  * department_name string \n\ne.g. location should be\n`hdfs://quickstart.cloudera:8020/user/hive/warehouse/hadoopexam.db/departments`\n\n\n2 . Please import data in existing table created above from `retaidb.departments` into hive table `hadoopexam.departments`.\n\n3 . Please import data in a non-existing table, means while importing create hive table named `hadoopexam.departments_new`"],"metadata":{}},{"cell_type":"markdown","source":["Answer"],"metadata":{}},{"cell_type":"markdown","source":["See the explanation for Step by Step Solution and configuration.\nExplanation:\nSolution :\n\nStep 1 : Go to hive interface and create database.\nhive\ncreate database hadoopexam;\n\nStep 2. Use the database created in above step and then create table in it. \nuse hadoopexam; \nshow tables;\n\nStep 3 : Create table in it.\ncreate table departments (department_id int, department_name string);\nshow tables;\ndesc departments;\ndesc formatted departments;\n\nStep 4 : Please check following directory must not exist else it will give error, hdfs dfs -Is\n/user/cloudera/departments\nIf directory already exists, make sure it is not useful and than delete the same.\nThis is the staging directory where Sqoop store the intermediate data before pushing in hive table.\nhadoop fs -rm -R departments\n\nStep 5 : Now import data in existing table\nsqoop import \\\n-connect jdbc:mysql://quickstart:3306/retail_db \\\n~ username=retail_dba \\\n-password=cloudera \\\n--table departments \\\n-hive-home /user/hive/warehouse \\\n-hive-import \\\n-hive-overwrite \\\n-hive-table hadoopexam.departments\n\nStep 6 : Check whether data has been loaded or not.\nhive;\nuse hadoopexam;\nshow tables;\nselect\" from departments;\ndesc formatted departments;\n\nStep 7 : Import data in non-existing tables in hive and create table while importing.\nsqoop import \\\n-connect jdbc:mysql://quickstart:3306/retail_db \\\n--username=retail_dba \\\n~ password=cloudera \\\n-table departments \\\n-hive-home /user/hive/warehouse \\\n-hive-import \\\n-hive-overwrite \\\n-hive-table hadoopexam.departments_new \\\n-create-hive-table\n\nStep 8 : Check-whether data has been loaded or not.\nhive;\nuse hadoopexam;\nshow tables;\nselect\" from departments_new;\ndesc formatted departments_new;"],"metadata":{}},{"cell_type":"markdown","source":["Activity 1\nin HIVE"],"metadata":{}},{"cell_type":"code","source":["CREATE DATABASE hadoopexam;\nUSE hadoopexam;\n\nCREATE TABLE departments(\n  department_id   int,\n  department_name string\n)\nFIELDS-TERMINATED-BY '\\T'\nSTORED hdfs://quickstart.cloudera:8020/user/hive/warehouse/hadoopexam.db/departments"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Activity 2.\nsqoop"],"metadata":{}},{"cell_type":"code","source":["sqoop import \n--connect jdbc:mysql://quickstart:3306/retail_db\n--username=retail_dba\n--password=cloudera\n--table      departments\n--hive-home /user/hive/warehouse \n--hive-import\n--hive-overwrite\n--hive-table hadoopexam.departments"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### Activity 3"],"metadata":{}},{"cell_type":"code","source":["sqoop import \n--connect jdbc:mysql://quickstart:3306/retail_db\n--user=retail_dba\n--password=cloudera\n--fields-terminated-by '\\t'\n--table departments\n\n--hive-home /user/hive/warehouse \n--hive-import \n--hive-overwrite \n--hive-table hadoopexam.departments_new \n--create-hive-table"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["sqoop import --connect jdbc:mysql://quickstart:3306/retail_db --username=retail_dba --password=cloudera --table      departments --hive-import --hive-overwrite --hive-table hadoopexam.departments"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"name":"p21","notebookId":2989818111360347},"nbformat":4,"nbformat_minor":0}
